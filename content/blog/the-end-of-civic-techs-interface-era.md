---
title: The end of civic tech's interface era
description: "Generative AI means we need to rethink the way we think about interfaces."
date: 2025-08-04
tags:
  - AI
  - government
  - design
---

<span class="note">This post was co-authored with Mark Headd, my colleague at Ad Hoc and a brilliant thinker and doer on technology and government. It's less a prediction than a provocation, playing out one possible consequence of generative AI to its logical endpoint. Check out [Mark's blog](https://civic.io/) and [follow him on LinkedIn](https://www.linkedin.com/in/markheadd/) for more of his great writing.</span>

There are lots of ways to answer the question "what does a civic technologist do," but a decent umbrella description is: work to bridge the gap between people and government by designing and building better digital interfaces. We organize information, build user-focused digital solutions, streamline forms, and redesign websites. This will, we hope, make government services more accessible, efficient, and user-friendly.

This work has operated under an assumed premise so fundamental that it's rarely made explicit: That the digital interfaces we build when people interact with governments are themselves highly valuable. From this, it follows that the value of our work is embedded and reflected in the design and technical proficiency with which these interfaces are implemented.

It's not surprising that the civic tech world has largely metabolized the rise of Artificial Intelligence (AI) as a set of tools we can use to make these interfaces *even better*. Chatbots! [Accessible PDFs!](https://codeforamerica.org/news/our-ai-solution-to-governments-pdf-problem/) These are good and righteous efforts that make things easier for government employees and better for the people they serve. But they're sitting on a fault line that AI is shifting beneath our feet: What if the primacy and focus we give *interfaces, *and the constraints we've accepted as immutable, are changing?

### The old paradigm: the interface is all

"Humans interacting with graphical user interfaces through the browser" - that's what the web…*is*. Right? So why *wouldn't* we consider the interface to be the definitive digital expression of a federal agency to its customers? But if you shift this from a rhetorical question to an actual one, you find that this paradigm rests on three key assumptions:

**Fixed, durable designs**: Once launched, an interface becomes relatively static. It is (hopefully) improved incrementally based on user feedback and changing needs. About once a decade, some combination of new political appointees and end-of-life technologies will cause someone to utter the dreaded *redesign* word. Barring that, frequent, large-scale changes to an agency's website are expensive, time-consuming, and risky because a single change affects every user.

**Multitenant by necessity**: Everyone uses essentially the same interface. There are limited variations for different devices, languages, or accessibility needs. Mobile users and desktop users will typically see different manifestations of the same interface. But the [same scaffolding](https://developer.mozilla.org/en-US/docs/Learn_web_development/Core/CSS_layout/Responsive_Design) is typically used to serve these different user groups. 

**High expertise requirements**: Because we have just one basic scaffolding to work with, we take a utilitarian view, using techniques like personas, card sorts, web analytics, and top tasks to approximate and serve the median user. Techniques require technicians: Building quality government websites has traditionally required teams of UX designers, developers, content strategists, and accessibility experts working together to produce the interface that the user ultimately sees. Because these interfaces represent business processes often encoded in law or regulation, these teams also expend effort designing and constructing the optimal user journey. 

### Enter just-in-time interfaces

AI upsets each one of these old assumptions both [conceptually and practically](https://signalpath.substack.com/p/just-in-time-interfaces):

>Just-in-Time UI is an emerging design paradigm that shifts the burden of navigation away from the user, and instead delivers the right interface at the right moment, in the right context. Where traditional interfaces rely on static screens, fixed menus, and user-initiated flows, Just-in-Time UI reimagines the interaction model.

Modern generative AI tools can assemble complex, high-fidelity interfaces quickly and cheaply. If you're a civic designer used to hand-crafting bespoke interfaces with care, the idea of just-in-time interfaces in production makes your hair stand on end. Us, too. The reality is, this is still an idea that lies in the future. But the future is getting here very quickly.

Shopify, with its [5M DAUs and $292B processed annually](https://www.demandsage.com/shopify-statistics/), is [doing its internal prototyping](https://x.com/postcarl/status/1942616904952340827) with generative AI. Delivering production UIs this way is gaining steam both [in theory](https://isolutions.medium.com/ephemeral-ui-in-ai-generated-on-demand-interfaces-81dbc8cd4579) and in proof-of-concept (e.g., [adaptive UIs](https://arxiv.org/abs/2405.09255#), Fred Hohman's [Project Biscuit](https://fredhohman.com/papers/biscuit), Sean Grove's [ConjureUI demo](https://www.youtube.com/watch?v=xgi1YX6HQBw)). The idea is serious enough that Google, not a slouch in the setting-web-standards game, is getting into the mix with [Stitch](https://developers.googleblog.com/en/stitch-a-new-way-to-design-uis/) and [Opal](https://developers.googleblog.com/en/introducing-opal/). AWS is [throwing its hat in the ring too](https://partyrock.aws/). Smaller players like [BuildAI](https://www.buildai.space/), [Replit](https://replit.com/ai), [Figma](https://www.figma.com/ai/), and [Camunda](https://camunda.com/) are exploring LLM-driven UI generation and workflow design. All of these *at first* may generate wacky interfaces and [internet horror stories](https://archive.is/ExLk7), and right now they're mostly focused on dynamic UI generation for a *developer*, not a *user*. But these are all different implementations of an idea that are converging on a clear endpoint, and if they can get into use at any substantial scale, they will become more reliable and production ready very quickly.

Civic designers shouldn't fear this future; we've been preparing for it. The Shopify tool mentioned above works in part because their [design system is built on tokens](https://medium.com/eightshapes-llc/tokens-in-design-systems-25dd82d58421), named variables that store key aspects of a design system. Tokens aren't new and aren't rocket science, but they are a best practice. You know which other design systems are tokenized? The [U.S. Web Design System](https://designsystem.digital.gov/design-tokens/), the [VA.gov Design System](https://design.va.gov/foundation/design-tokens), the [National Cancer Institute Design System](https://designsystem.cancer.gov/foundations), the [State of Colorado Design System](https://dcs.colorado.gov/ids/digital-guidelines/design-tokens), and many, many others. Tokens aren't *sufficient* to make just-in-time UIs a reality, but they probably are *foundational*, and thanks to USWDS and its progeny, they are near ubiquitous in dot-gov domains.

The point is this: civic designers have both a strong foundation and a growing imperative to think seriously about what government websites will look like in a world of just-in-time UI generation.

### Humans-centered design

It's often said that "creativity loves constraints," and today's dot-gov ecosystem reflects the constraints of its builders. Civic designers build government websites for the median user and try to offer top-tasks and no-wrong-doors because, for the most part, we have to pick one basic interface for everyone. But if just-in-time UIs erodes this constraint, we can see the edges of a new approach to delivering improved government services via the web:

**Adaptive, Context-Specific Interactions**: Instead of designing one interface that works acceptably for everyone, and must be managed and scaled that way, AI will make it possible to generate variations tailored to specific circumstances. A single parent applying for childcare assistance in their state might see a completely different interface than a recent college graduate seeking benefits under the same program–a different information architecture, different interaction patterns, and different support options. A user whose natural language input indicates they're eligible for two different benefits programs might be served a dynamically-generated form that applies for both simultaneously. Deciding what to present when will be a matter not of documenting discrete personas and user journeys, but of training and guiding a generative AI model. While core navigation and other elements can remain consistent, the specific guidance, information hierarchy, and interactive elements can be tailored to each user's specific situation. 

**Expertise Moves Upstream**: The expertise needed to build high-quality digital services will move upstream–from implementation to architecture, from specific solutions to systemic standards. Civic tech experts will focus on creating and refining the building blocks, standards, and business logic that AI systems use to tailor interfaces on demand. UX designers will shift from crafting individual screens to defining interaction principles and component libraries, and from hand-coding each UI element to deciding which elements should be dynamically generated or held constant over time. Content strategists will develop frameworks for how information should be structured and presented across different contexts. This kind of UX infrastructure, today often thought of as "bonus features" of a web modernization effort, will instead become *foundational*, comprising a kind of [alignment](https://en.wikipedia.org/wiki/AI_alignment) that is focused on maintaining visual identity and interaction guardrails.

**Defining Policy as Code**: Design is more than how a website looks, and just-in-time interfaces will need more than a prompt and a design system to generate a coherent web workflow for filing taxes or applying for public benefits. To bridge the gap between *prototyping or coding* with AI and *generating just-in-time interfaces in production*, we also have to invest in [encoding the business logic](https://digitalgovernmenthub.org/get-involved/digital-benefits-network-rules-as-code-community-of-practice/) that users have to traverse in ways that generative AI systems can understand. Tools and formats like [BPMN/DMN](https://bpmn.io/), [Rego](https://www.openpolicyagent.org/docs/policy-language), and [Catala](https://catala-lang.org/en/examples/us-tax-code) offer models for encoding policy, and generative AI can [build pipelines for translation](https://adhoc.team/2024/09/25/ai-policy-to-code/). As with design systems, the just-in-time UI world will see civic researchers and designers focus less on how a particular form looks, and more on specifying the visual, policy, and process ingredients that generative AI can combine to meet a user's needs.

### The opportunity ahead

We are at an inflection point in civic technology. The same AI capabilities transforming other sectors will revolutionize how people interact with their government. Realizing this potential requires rethinking our role as civic technologists. Instead of building fixed solutions, we need to become architects of adaptive systems. Instead of designing for the average user, we need to create frameworks that can be adapted into interfaces that meet a person's unique circumstances.

While these are radically new *ways* of designing experiences, the *purpose* of designing them is the same as it always was: Putting the user at the center of the interaction. Just-in-time interfaces aren't inevitable; to adopt them, public sector agencies will have to have a high tolerance for disrupting team structures and embracing risk. But if implemented responsibly, the potential payoff is staggering: We can design interfaces for *actual users*, not lossy simulacra defined by personas and bounce rates. We can flex experiences dynamically to meet individual users' reading levels, socioeconomic context, and most urgent priorities.

To do this, we need to change the way we think about the interfaces that people use to transact and interact with government agencies. We have to design from the start with the intention to move from fixed, costly, multitenant experiences to adaptive, tailored, highly individualized ones.

More than a decade ago, when the civic tech movement reorganized itself after its fledgling early years around the principles of a user's experience with online government services, we put the interfaces we build at the center of the civic tech universe. If we're going to realize the benefits that AI can bring to the way that people interact with their government, we need to change our way of thinking about what interfaces are, how people use them, and most importantly, how we build them.
