<!doctype html>
<html lang="en">
	<head>





		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		
<title>AI thinking, fast and slow</title>
<meta property="og:title" content="AI thinking, fast and slow">


<meta property="og:image" content="https://danmu.nz/og-images/ai-thinking-fast-and-slow.png">
<meta property="og:image:secure_url" content="https://danmu.nz/og-images/ai-thinking-fast-and-slow.png">
<meta name="twitter:image" content="https://danmu.nz/og-images/ai-thinking-fast-and-slow.png">




<meta name="description" content="Hierarchical Reasoning Models have intriguing potential for the public sector, because they &#39;think&#39; more like we do.">
<meta property="og:image:width" content="1200">
<meta property="og:image:height" content="630">
<meta property="og:image:type" content="image/png">
<meta name="twitter:card" content="summary_large_image">



		
		
		
		<link rel="alternate" href="/feed/feed.xml" type="application/atom+xml" title="Dan Munz">
		<link rel="preconnect" href="https://fonts.googleapis.com">
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
		
<link href="https://fonts.googleapis.com/css2?family=Bricolage+Grotesque:opsz,wdth,wght@12..96,75..100,200..800&family=DM+Mono:ital,wght@0,300;0,400;0,500;1,300;1,400;1,500&family=IBM+Plex+Serif:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&family=Oswald:wght@200..700&display=swap" rel="stylesheet">

		<link rel="me" href="https://github.com/danmunz">
		<link rel="me" href="https://www.linkedin.com/in/danmunz/">
		<link rel="me" href="https://bsky.app/profile/danmunz.bsky.social/">

		<meta name="generator" content="Eleventy v3.1.2">

		
		

	
		<style>:root {
    /* — Typography & Layout — */
    --font-body: normal 300 1rem/1.5rem "Bricolage Grotesque", system-ui,
        sans-serif;
    --font-headings: normal 400 3.5rem "Oswald", sans-serif;
    --font-monospace: "DM Mono", Consolas, Menlo, Monaco, monospace;
    --font-serif: "IBM Plex Serif", Georgia, serif;

    /* — Slate & Sky Palette — */
    --color-gray-20: #ebf5ff; /* pill & border */
    --color-gray-50: #6c7b8a; /* metadata, comments */
    --color-gray-90: #333; /* body text */

    --background-color: #fcfdfe; /* page background */
    --text-color: var(--color-gray-90);

    --text-color-link: #42a5f5; /* link & accent */
    --text-color-link-active: #1e88e5; /* link hover */
    --text-color-link-visited: #357ac3; /* visited links */

    --syntax-tab-size: 2;
}

/* Global stylesheet */
* {
    box-sizing: border-box;
}

body,
main,
article,
.Footnotes,
footer {
    box-sizing: border-box;
}

@view-transition {
    navigation: auto;
}

html,
body {
    padding: 0;
    margin: 0 auto;
    font: var(--font-body);
    color: var(--text-color);
    background-color: var(--background-color);
}

html {
    overflow-y: scroll;
}

body {
    max-width: 40em;
    counter-reset: footnotes;
}

/* https://www.a11yproject.com/posts/how-to-hide-content/ */
.visually-hidden:not(:focus):not(:active) {
    clip: rect(0 0 0 0);
    clip-path: inset(50%);
    height: 1px;
    overflow: hidden;
    position: absolute;
    white-space: nowrap;
    width: 1px;
}

/* Fluid images via https://www.zachleat.com/web/fluid-images/ */
img {
    max-width: 100%;
}
img[width][height] {
    height: auto;
}
img[src$=".svg"] {
    width: 100%;
    height: auto;
    max-width: none;
}
video,
iframe {
    width: 100%;
    height: auto;
}
iframe {
    aspect-ratio: 16/9;
}

p:last-child {
    margin-bottom: 0;
}
p {
}

li {
    line-height: 1.5;
}

ul {
}

/* Links */

a[href] {
    color: var(--text-color-link-active);
    transition: 0.3s;
}

a[href]:hover,
a[href]:active {
    color: var(--text-color-link-visited);
    transition: 0.3s;
}

main {
    padding: 1rem;
    font-size: 1.1rem;
    color: var(--text-color);
    line-height: 1.6;
}

footer {
    border-top: solid 1px #eee;
    font-size: 0.75rem;
    padding: 0.75em 1.5em;
    margin: 0 0 1em 0;
    background: none;
    /* NO max-width or margin-left/right! */
}

article:first-child {
    margin-top: 0;
}

header {
    border-bottom: 1px solid #eee;
}

#skip-link {
    text-decoration: none;
    background: var(--background-color);
    color: var(--text-color);
    padding: 0.5rem 1rem;
    border: 1px solid var(--color-gray-90);
    border-radius: 2px;
}

/* Prevent visually-hidden skip link fom pushing content around when focused */
#skip-link.visually-hidden:focus {
    position: absolute;
    top: 1rem;
    left: 1rem;
    /* Ensure it is positioned on top of everything else when it is shown */
    z-index: 999;
}

.links-nextprev {
    display: flex;
    justify-content: space-between;
    gap: 0.5em 1em;
    list-style: "";
    border-top: 1px dashed var(--color-gray-20);
    padding: 1em 0;
}
.links-nextprev > * {
    flex-grow: 1;
}
.links-nextprev-next {
    text-align: right;
}

table {
    margin: 1em 0;
}
table td,
table th {
    padding-right: 1em;
}

/* === Code blocks === */

/* Inline code */
code:not([class*="language-"]) {
    font-family: var(--font-monospace);
    background: rgba(66, 165, 245, 0.1);
    color: #324a5e;
    padding: 0.15em 0.4em;
    border-radius: 4px;
}

/* Prism-highlighted blocks */
pre[class*="language-"]:not(.language-text):not(.language-prompt) {
    position: relative;
    background: #2b2d42; /* graphite */
    color: #eceff4; /* ivory on dark */
    font-family: var(--font-monospace);
    font-size: 0.95em;
    line-height: 1.6;
    padding: 1.25em 1.5em;
    margin: 2em 0;
    border-left: 4px solid #42a5f5; /* sky accent */
    border-radius: 6px;
    overflow-x: auto;
    box-shadow: 0 2px 6px rgba(0, 0, 0, 0.15);
}

/* Fallback <pre> blocks */
pre:not([class*="language-"]) {
    background: #1e272e;
    color: #e2e8f0;
    font-family: var(--font-monospace);
    font-size: 0.95em;
    line-height: 1.25;
    padding: 1.25em 1.5em;
    margin: 2em 0;
    border-radius: 8px;
    overflow-x: auto;
    white-space: pre;
    box-shadow: 0 2px 6px rgba(0, 0, 0, 0.15);
}

/* Prose-style blocks */
pre.language-text,
pre.language-prompt,
code.language-text,
code.language-prompt {
    white-space: pre-wrap !important;
    word-break: break-word;
    overflow-wrap: anywhere;
    overflow-x: visible;
}

pre.language-text,
pre.language-prompt {
    background: #ebf5ff; /* pale sky */
    color: #2f3d34; /* dark body text */
    padding: 1.5em;
    margin: 2em 0;
    border-left: 4px solid #324a5e;
    border-radius: 6px;
    font-family: var(--font-monospace);
    font-size: 1em;
    line-height: 1.7;
    box-shadow: 0 1px 4px rgba(0, 0, 0, 0.04);
}

pre[class*="language-"]::before {
    content: attr(data-lang);
    position: absolute;
    top: 0.5rem;
    right: 0.75rem;
    font-size: 0.65em;
    font-family: var(--font-monospace);
    color: #ccc;
    background: rgba(255, 255, 255, 0.05);
    border: 1px solid rgba(255, 255, 255, 0.1);
    padding: 0.15em 0.5em;
    border-radius: 4px;
    text-transform: uppercase;
    pointer-events: none;
}

pre[class*="language-"] {
    position: relative;
}

.copy-button {
    position: absolute;
    top: 0.5rem;
    left: 0.75rem;
    font-size: 0.65em;
    font-family: var(--font-monospace);
    color: #ccc;
    background: rgba(255, 255, 255, 0.05);
    border: 1px solid rgba(255, 255, 255, 0.1);
    padding: 0.15em 0.5em;
    border-radius: 4px;
    cursor: pointer;
    opacity: 0.6;
    transition: opacity 0.2s;
}

.copy-button:hover {
    opacity: 1;
}

/* Header */
header {
    display: flex;
    gap: 1em;
    flex-wrap: wrap;
    justify-content: space-between;
    align-items: center;
    padding: 1em;
}

.home-link {
    font: var(--font-headings);
    flex-grow: 1;
    font-size: 1.5em;
    font-weight: 500;
    text-transform: uppercase;
    letter-spacing: -0.05em;
}
.home-link:link:not(:hover) {
    text-decoration: none;
}

/* Nav */
.nav {
    display: flex;
    gap: 0.5em 1em;
    padding: 0;
    margin: 0;
    list-style: none;
    font-size: 1.125em;
}
.nav-item {
    display: inline-block;
}
.nav-item a[href]:not(:hover) {
    text-decoration: none;
}
.nav a[href][aria-current="page"] {
    text-decoration: underline;
}

/* Headings */
h1,
h2,
h3,
h4,
h5,
h6 {
    font: var(--font-headings);
    color: #324a5e;
    line-height: 1.1;
    margin-top: 2.5rem;
    margin-bottom: 1rem;
    letter-spacing: -0.05em;
}

h1 {
    font-size: 4.5rem;
    color: var(--text-color-link-active);
    padding-bottom: 0.25em;
    margin: 0;
    text-shadow: 1px 1px #cccccc;
}

h2 {
    font-size: 2.5rem;
    margin-top: 2.5rem;
}

h3 {
    font-size: 2rem;
    color: var(--text-color-link-active);
}

h4 {
    font-size: 1.5rem;
    color: var(--text-color);
}

h5,
h6 {
    font-size: 1.1rem;
    color: var(--color-gray-50);
    font-weight: 500;
}

/* Posts list */
.postlist {
    list-style: none;
    padding: 0;
}
.postlist-item {
    margin-bottom: 2em;
 }

.postlist-desc,
.postlist-date {
    color: var(--color-gray-90);
    word-spacing: -0.5px;
    display: block;
}

.postlist-desc {
    letter-spacing: -0.01em;
}

.postlist-date {
    font-size: 0.85em;
    padding: 0 0 1px 0;
    line-height: 1;
}

.postlist-date::before{
content: "⊙";
font-size: 1em;
vertical-align: text-top;
color:var(--text-color-link-active);
padding: 0px 3px 0 0;
}

.postlist-link {
    font: var(--font-headings);
    font-size: 2.5rem;
    font-weight: 400;
    color: var(--text-color-link-active);
    margin: 0.25em 0 0.25em 0;
    line-height: 1;
    letter-spacing: -0.05em;
    display: block;
    text-decoration: none;
}

/*Post Metadata*/

.post-meta-row {
    display: flex;
    flex-wrap: nowrap;
    align-items: flex-start;
    gap: 1rem;
    margin-bottom: 1em;
}

.post-date {
    flex: 0 0 auto; /* don't grow or shrink */
    color: #666;
    min-width: 100px; /* or however wide you want your date column */
	font-size: .85em;
}

.tag-list {
    flex: 1 1 auto; /* fill remaining space */
    display: flex;
    flex-wrap: wrap;
    gap: 0.5em;
}

.tag-list > .post-tag {
    align-self: center;
}

.post-tag {
    background-color: var(--color-gray-20);
    color: #324a5e;
    border-radius: 999px;
    padding: 0em 0.7em;
    font-size: 0.75em;
    font-weight: 600;
    letter-spacing: 0.03em;
    text-transform: uppercase;
    text-decoration: none;
    border: solid 1px #ccc;
    white-space: nowrap;
}

/*Post content*/

article {
    padding: 1.1em 0 0 0;
    letter-spacing: -0.01em;
}

main {
    font-optical-sizing: auto;
}
.post-content img{
border: solid 2px var(--color-gray-90);
}


.post-content p {
    margin-top: 0;
    margin-bottom: 1.2em;
    }

.post-content li {
    margin-bottom: 0.75em;
}

.post-content strong,
.post-content b {
    font-weight: 600;
}

.note{
background-color: #fce4a18e;
display: block;
width: 100%;
font-weight: 300;
padding: 12px 14px;
border-radius: 6px;
font-size: .9em;
line-height: 1.5;
box-shadow: 0 2px 6px rgba(0, 0, 0, 0.15);
}

blockquote {
    font-family: var(--font-serif);
    font-weight: 400;
    font-style: normal;
    font-size: 0.95em;
    line-height: 1.6;
    color: #1d2f3d;
    background-color: rgba(66, 165, 245, 0.05);
    border-left: 2px solid #42a5f5;
    padding: 0.1rem 1.5rem;
    margin: 1rem 0;
    position: relative;
    quotes: "“" "”" "‘" "’";
}

blockquote p:first-of-type {
    margin-top: 1em;
}

blockquote p:first-of-type::before {
    content: open-quote;
    font-size: 1.5em;
    line-height: 0.2em;
    vertical-align: -0.4em;
    margin-right: 0.2em;
}

blockquote p:last-of-type::after {
    content: close-quote;
    font-size: 1.5em;
    line-height: 0.2em;
    vertical-align: -0.4em;
    margin-left: 0.2em;
}

/*Footnotes*/

.Footnotes {
    margin: 2em 0 1em 0;
    padding: 1em 1.5em;
    background: #f0f0f0;
    border-radius: 8px;
    /* NO max-width or margin-left/right! */
}

@media (min-width: 1024px) {
    .Footnotes {
        /* Remove width, left, and weird padding overrides. */
        padding: 1em 1.5em;
    }
}

.Footnotes__title {
    font-size: 150%;
    margin: 0;
}

.Footnotes__list {
    font-size: 110%;
    margin-left: 0;
    padding-left: 2em;
}

.Footnotes__list-item:not(:last-child) {
    margin: 1em 0;
}

.Footnotes__ref[role="doc-noteref"] {
    background-image: none;
    cursor: default;
    text-decoration: none;
}

.Footnotes__ref[role="doc-noteref"]::after {
    content: counter(footnotes);
    counter-increment: footnotes;
    vertical-align: super;
    font-size: 0.6em;
    margin-left: 2px;
    font-weight: 600;
    display: inline-block;
    padding: 0 4px;
    text-decoration: none;
    cursor: pointer;
    background-color: #dedede;
    color: var(--color-gray-90);
    transition: 0.2s;
}

.Footnotes__ref[role="doc-noteref"]:focus::after,
.Footnotes__ref[role="doc-noteref"]:hover::after {
    background-size: inherit;
    background-color: var(--text-color-link);
    color: #fff;
    transition: 0.2s;
}

/*Tables in posts*/
table {
    width: 100%;
    border-collapse: collapse;
    font-size: 0.8rem; /* smaller font */
}

th,
td {
    padding: 0.5em 0.75em;
    border: 1px solid #ccc;
    text-align: left;
    vertical-align: top;
}

thead,
td:nth-child(1) {
    background-color: var(--color-gray-20);
    font: var(--font-headings);
    font-size: 1.1em;
}

th {
    font-weight: 400;
    color: #333;
    text-align: center;
}

tbody tr:nth-child(even) {
    background-color: #f9f9f9; /* alternating row color */
}

tbody tr:nth-child(odd) {
    background-color: #fff;
}
/* Layout inherited from index.css */
code[class*="language-"],
pre[class*="language-"] {
  background: inherit;
  color: inherit;
}

/* Gentle token palette */
.token.comment,
.token.prolog,
.token.doctype {
  color: #6C7B8A;    /* slate-gray */
  font-style: italic;
}

.token.keyword {
  color: #42A5F5;    /* sky-blue */
}

.token.string {
  color: #3CBAB2;    /* teal */
}

.token.function {
  color: #8C6DA5;    /* lilac */
  font-weight: 600;
}

.token.number,
.token.boolean {
  color: #B48EAD;    /* muted purple */
}

.token.operator,
.token.punctuation {
  color: #A0AEC0;    /* soft gray */
}

.token.variable,
.token.attr-name {
  color: #4C6272;    /* storm-slate */
}</style>
		
		


	</head>


<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-PM95BS3TNB"></script>






	<body>
					
		<a href="#main" id="skip-link" class="visually-hidden">Skip to main content</a>

		<header>
			<a href="/" class="home-link">Dan Munz</a>
			<nav>
				<h2 class="visually-hidden" id="top-level-navigation-menu">Top level navigation menu</h2>
				<ul class="nav">
					<li class="nav-item"><a href="/">Home</a></li>
					<li class="nav-item"><a href="/blog/">Archive</a></li>
					<li class="nav-item"><a href="/about/">About</a></li>
					<li class="nav-item"><a href="/feed/feed.xml">Feed</a></li>
				</ul>
			</nav>
		</header>

		<main id="main">
			<heading-anchors>
				<!--
<style>/**
 * okaidia theme for JavaScript, CSS and HTML
 * Loosely based on Monokai textmate theme by http://www.monokai.nl/
 * @author ocodia
 */

code[class*="language-"],
pre[class*="language-"] {
	color: #f8f8f2;
	background: none;
	text-shadow: 0 1px rgba(0, 0, 0, 0.3);
	font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
	font-size: 1em;
	text-align: left;
	white-space: pre;
	word-spacing: normal;
	word-break: normal;
	word-wrap: normal;
	line-height: 1.5;

	-moz-tab-size: 4;
	-o-tab-size: 4;
	tab-size: 4;

	-webkit-hyphens: none;
	-moz-hyphens: none;
	-ms-hyphens: none;
	hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
	padding: 1em;
	margin: .5em 0;
	overflow: auto;
	border-radius: 0.3em;
}

:not(pre) > code[class*="language-"],
pre[class*="language-"] {
	background: #272822;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
	padding: .1em;
	border-radius: .3em;
	white-space: normal;
}

.token.comment,
.token.prolog,
.token.doctype,
.token.cdata {
	color: #8292a2;
}

.token.punctuation {
	color: #f8f8f2;
}

.token.namespace {
	opacity: .7;
}

.token.property,
.token.tag,
.token.constant,
.token.symbol,
.token.deleted {
	color: #f92672;
}

.token.boolean,
.token.number {
	color: #ae81ff;
}

.token.selector,
.token.attr-name,
.token.string,
.token.char,
.token.builtin,
.token.inserted {
	color: #a6e22e;
}

.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string,
.token.variable {
	color: #f8f8f2;
}

.token.atrule,
.token.attr-value,
.token.function,
.token.class-name {
	color: #e6db74;
}

.token.keyword {
	color: #66d9ef;
}

.token.regex,
.token.important {
	color: #fd971f;
}

.token.important,
.token.bold {
	font-weight: bold;
}
.token.italic {
	font-style: italic;
}

.token.entity {
	cursor: help;
}
</style>
<style>* New diff- syntax

pre[class*="language-diff-"] {
	--eleventy-code-padding: 1.25em;
	padding-left: var(--eleventy-code-padding);
	padding-right: var(--eleventy-code-padding);
}

.token.deleted {
	background-color: hsl(0, 51%, 37%);
	color: inherit;
}
.token.inserted {
	background-color: hsl(126, 31%, 39%);
	color: inherit;
}

/* Make the + and - characters unselectable for copy/paste */
.token.prefix.unchanged,
.token.prefix.inserted,
.token.prefix.deleted {
	-webkit-user-select: none;
	user-select: none;
	display: inline-flex;
	align-items: center;
	justify-content: center;
	padding-top: 2px;
	padding-bottom: 2px;
}
.token.prefix.inserted,
.token.prefix.deleted {
	width: var(--eleventy-code-padding);
	background-color: rgba(0,0,0,.2);
}

/* Optional: full-width background color */
.token.inserted:not(.prefix),
.token.deleted:not(.prefix) {
	display: block;
	margin-left: calc(-1 * var(--eleventy-code-padding));
	margin-right: calc(-1 * var(--eleventy-code-padding));
	text-decoration: none; /* override del, ins, mark defaults */
	color: inherit; /* override del, ins, mark defaults */
}
</style>
-->




<h1 id="ai-thinking-fast-and-slow">AI thinking, fast and slow</h1>

<div class="post-meta-row">
  <div class="post-date">
    <time datetime="2025-08-02">
      August 2, 2025
    </time>
  </div>

  <div class="tag-list">
      <a href="/tags/ai/" class="post-tag">AI</a>
      <a href="/tags/llms/" class="post-tag">LLMs</a>
      <a href="/tags/government/" class="post-tag">government</a>
      <a href="/tags/chatgpt/" class="post-tag">ChatGPT</a>
  </div>
</div>

<article class="post-content">
<p>I'm increasingly intrigued by a concept called Hierarchical Reasoning Models (HRM), a potential alternative architecture to traditional LLMs.<a class="Footnotes__ref" href="#traditional-llms-note" id="traditional-llms-ref" aria-describedby="footnotes-label" role="doc-noteref"></a> Last month, Sapient released an <a href="https://github.com/sapientinc/HRM">open-source HRM</a> and accompanying <a href="https://arxiv.org/abs/2506.21734">paper</a>. The paper is written in the kind of prose you'd expect from nine mathematics PhDs<a class="Footnotes__ref" href="#math-phd-prose-note" id="math-phd-prose-ref" aria-describedby="footnotes-label" role="doc-noteref"></a>, but as far as I can tell, the basic idea is this:</p>
<p>LLMs &quot;reason&quot; one word or concept at a time. This causes a limitation that the HRM paper authors call &quot;brittle task decomposition,&quot; an academic way of saying that a flaw in one link in the chain of reasoning can derail the whole thing.<a class="Footnotes__ref" href="#icebreaker-linear-thinking-note" id="icebreaker-linear-thinking-ref" aria-describedby="footnotes-label" role="doc-noteref"></a> You can debate how big a problem this is; even general-purpose LLMs are incredibly capable tools. But HRMs, at least in theory, reason more like we do:</p>
<blockquote>
<p>The human brain provides a compelling blueprint for achieving the effective computational depth that contemporary artificial models lack. It organizes computation hierarchically across cortical regions operating at different timescales, enabling deep, multi-stage reasoning. Recurrent feedback loops iteratively refine internal representations, allowing slow, higher-level areas to guide, and fast, lower-level circuits to execute—subordinate processing while preserving global coherence.</p>
</blockquote>
<p>In other words, HRM outputs are governed by distinct processes working at different speeds, with &quot;slower,&quot; more deliberative background processes governing faster, more impulsive ones. This separation of cognitive concerns will be familiar to readers of Kahneman's <em><a href="https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow">Thinking, Fast and Slow</a></em>, which the authors explicitly credit as inspiration:</p>
<blockquote>
<p>The brain dynamically alternates between automatic thinking...and deliberate reasoning. Neuroscientific evidence shows that these cognitive modes share overlapping neural circuits, particularly within regions such as the prefrontal cortex and the default mode network...Inspired by the above mechanism, we incorporate an adaptive halting strategy into HRM that enables “thinking, fast and slow”.</p>
</blockquote>
<p>Again, a smarter person than me might read this paper/model and call it bunk, but assuming it's conceptually sound, there are a few reasons I think this is exciting especially for public sector applications:</p>
<ul>
<li><strong>They're open-source (at least, this one is).</strong> This isn't a <em>feature</em> of HRMs and there are <a href="https://github.com/eugeneyan/open-llms">plenty of open-source LLMs</a>, but it's a good thing that HRM development is starting in earnest in a transparent, auditable way.</li>
<li><strong>They break the size-quality paradigm.</strong>  HRMs are less compute- and cost-intensive. This reduces the &quot;success penalty&quot; for AI adoption, and presents a model of improving LLM performance that isn't just <code>MOAR TOKENZ!!1!</code>. Emerging evidence (and common sense) suggests that ginormous context windows increase cost without increasing–and in some cases, degrading–quality. HRMs are a nice reminder to government buyers to demand smarter architectures for their taxpayer dollar, not just <em>bigness</em>.</li>
<li><strong>Public services have context.</strong> I'd like to think we'll only ever use AI to eliminate toil, but it's inevitable that it will be put in-the-loop on benefits adjudication, financial aid decisions, FDA approvals, etc. On paper these are clear, stepwise processes; in reality, they take place against a background of novel individual circumstances, regulatory and legal frameworks, and small-p political initiatives. Can a linear LLM, even with an infinite context window, consider factors like these in a timely and non-budget-exploding way? HRMs' ability to run latent reasoning and revisit prior steps makes it at least <em>plausible</em> that with the right rule-based inputs they could more reliably &quot;sanity-check&quot; outcomes against the intent of laws, regulations, and policy initiatives, and prioritize fairness and precedent alongside speed and compliance.</li>
<li><strong>Less random lying!</strong> LLMs work by guessing at what someone who just said the <em>last</em> thing it said would say next. We have a word for humans who think this way: sociopaths. LLMs reason themselves into corners they have to lie to get out of. Sometimes this manifests as ChatGPT asking if you'd like a Word document, apparently <a href="https://www.reddit.com/r/ChatGPT/comments/1jrsb0e/chatgpt_offering_to_create_word_document_lying_it/">forgetting that it doesn't have the ability to make Word documents</a>. Other times, it <a href="https://amandaguinzburg.substack.com/p/diabolus-ex-machina">offers edits on content it hasn't read</a>. Or <a href="https://www.reddit.com/r/ChatGPT/comments/1m4lsso/replit_ai_went_rogue_deleted_a_companys_entire/">deletes an entire production database</a>:<br><br><blockquote class="reddit-embed-bq" style="height:500px" data-embed-height="740"><a href="https://www.reddit.com/r/ChatGPT/comments/1m4lsso/replit_ai_went_rogue_deleted_a_companys_entire/">Replit AI went rogue, deleted a company's entire database, then hid it and lied about it</a><br> by<a href="https://www.reddit.com/user/MetaKnowing/">u/MetaKnowing</a> in<a href="https://www.reddit.com/r/ChatGPT/">ChatGPT</a></blockquote><script async="" src="https://embed.reddit.com/widgets.js" charset="UTF-8"></script><br>Not great! I am admittedly departing into speculation here, but HRMs <em>seem</em> less likely to engage in this kind of behavior. By design, they can think before they speak and form complete answers, retrace their steps and take more time if needed, and keep what they've said in distinct working memory. As far as I know there's been no head-to-head testing on this, but there's already evidence that <a href="https://arxiv.org/abs/2310.06271">prompting self-reflection reduces hallucinations in LLMs</a>–HRMs seem to just bake this idea into the architecture.</li>
</ul>
<p>Federal agencies are <a href="https://www.gao.gov/products/gao-25-107653">adopting AI with startling speed</a>, which seems risky, but maybe less risky than getting left behind. HRMs offer at least a foundation for a more appealing third option, and push us to look for more sophisticated and more efficient architectures, not just more and bigger AI.</p>

</article>


  <footer role="doc-endnotes" class="Footnotes">
    <h2 id="footnotes-label" class="Footnotes__title">Footnotes</h2>
    <ol class="Footnotes__list"><li id="traditional-llms-note" class="Footnotes__list-item">It feels odd to refer to LLMs as 'traditional', but here we are in the future I guess. <a class="Footnotes__back-link" href="#traditional-llms-ref" aria-label="Back to reference 01" role="doc-backlink">↩</a></li>
<li id="math-phd-prose-note" class="Footnotes__list-item">I have no idea what academic credentials the authors actually have. This statement is nonetheless an accurate description of the paper. <a class="Footnotes__back-link" href="#math-phd-prose-ref" aria-label="Back to reference 11" role="doc-backlink">↩</a></li>
<li id="icebreaker-linear-thinking-note" class="Footnotes__list-item">If you want to simulate this yourself, head to a <a href="https://www.parabol.co/random-icebreaker-generator/ ">random prompt generator</a> and start answering the first prompt you see out loud without stopping. (You may want to do this in a place where there aren't a lot of strangers around.) Notice how...unnatural this feels? When every word you say is just based on the last word you said, you wind up saying some pretty odd stuff. This is how LLMs talk all the time. That's a gross simplification, but it gives you an idea of the problem. <a class="Footnotes__back-link" href="#icebreaker-linear-thinking-ref" aria-label="Back to reference 21" role="doc-backlink">↩</a></li></ol>
  </footer>
<ul class="links-nextprev"><li class="links-nextprev-prev">← Previous<br> <a href="/blog/a-few-thoughts-on-seeing-the-pixies-live/">A few thoughts on seeing The Pixies live</a></li><li class="links-nextprev-next">Next →<br><a href="/blog/the-end-of-civic-techs-interface-era/">The end of civic tech&#39;s interface era</a></li>
</ul>


			</heading-anchors>
		</main>

		<footer>
			<p center="">
				Built with <a href="https://www.11ty.dev/">Eleventy v3.1.2</a>. Full colophon <a href="/about/#colophon">here</a>.
			</p>
		</footer>

		<!-- This page `/blog/ai-thinking-fast-and-slow/` was built on 2026-01-21T13:24:49.924Z -->
		<script type="module" src="/dist/smF4OImz_W.js"></script>
	</body>
</html>
